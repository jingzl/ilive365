## 第7章 大模型应用原理
重点讲解大模型微调技术原理、模型部署时使用的量化技术，以及应用开发涉及的AI Agent框架。
### 7.1 大模型微调原理
各行业都在构建各自的垂域大模型。构建垂域大模型有很多关键技术，其中大模型微调技术在此过程中起到了非常关键的作用。它充分利用通用模型的基础能力，通过垂域数据微调模型参数，既提高了大模型的生成效率，又增强了其适应性，使其能在不同行业的应用场景中发挥巨大的价值。
#### 7.1.1 大模型微调定义
大模型微调的定义是在已经预训练好的大型深度学习模型基础上，使用新的、针对特定任务的数据集对模型进行进一步训练的过程。
#### 7.1.2 大模型微调应用场景
实际应用大模型时，微调涉及以下几个关键步骤：
1）选择预训练模型
2）准备新任务数据集
3）选择微调方式
4）进行微调训练
5）评估与调优
大模型微调的优势在于能够充分利用预训练模型的通用特征，并在少量新数据的基础上快速适应新的任务需求。
#### 7.1.3 大模型微调方法总结
大语言模型微调是一种有监督学习，通过标注数据集来更新模型权重，从而提高模型处理特定任务的能力。
**1）指令微调**
指令微调是在由指令输出对组成的数据集上进一步训练大语言模型的过程。其中，指令是用户给出的明确指示，输出是执行这些指令后得到的预期结果。
指令微调是有监督微调的一种特殊形式，但其目标有所不同。监督微调是使用标注数据（也就是说只有带标签的数据）对预训练模型进行微调的方法，以便模型能够更好地执行特定任务。指令微调则是为了增强模型的能力和可控性。指令微调的特殊之处在于其数据集结构，该数据集包含人类指令及其对应的期望输出，这使模型专注于理解和遵循指令。
**2）全微调**
全微调（Full Fine-Tuning，FFT） 是更新模型所有权重的过程。这个过程会产生一个具有更新权重的新模型版本。需要注意的是，与预训练一样，全微调需要大量的内存和计算资源来存储和处理训练过程中的所有梯度、优化器和其他更新组件。
**3）参数高效微调**
参数高效微调（Parameter-Efficient Fine-Tuning，PEFT）是训练语言模型的一项计算密集型任务。与全微调相比，进行参数高效微调所需内存有较大不同。全微调时，内存不仅要用于存储模型，还要存储训练过程中必要的参数。计算机可能能够处理模型权重，但在训练过程中为优化状态、梯度和前向激活分配足够的内存通常存在困难。而参数高效微调旨在减少这种内存需求。从成本和效果的角度综合考虑，PEFT是目前业界比较流行的微调方法。这里详细介绍几种比较流行的PEFT方案。
① Prompt Tuning
Prompt Tuning的出发点是基座模型（Foundation Model）的参数不变，为每个特定任务训练一个包含少量参数的小模型，在具体执行特定任务时按需调用。Prompt Tuning是现在大模型微调常用的一种方法，其经历了多个版本（包括Prefix-Tuning、P-Tuning v1、Parameter-Efficient Prompt Tuning和P-Tuning v2）的演进。
② LoRA
LoRA采用了与Prompt Tuning和Prefix-Tuning完全不相同的技术路线。LoRA有一个核心假设：我们现在看到的这些大语言模型，都是被过度参数化的。而过度参数化的大模型背后，往往有一个低维的本质模型。
LoRA假设模型在学习过程中权重的变化具有较低的“内在秩”，从而提出低秩适应（LoRA）方法。LoRA基于大模型的内在低秩特性，通过增加旁路矩阵来模拟全参数微调。这是目前最通用、效果最好的微调方法之一，并且它能和其他参数高效微调方法有效结合。
③ QLoRA
量化（Quantization）是一种在保证尽可能不降低模型性能的前提下，通过降低参数的精度，来减少计算资源需求的方法。量化的核心目标是降低成本，包括降低训练成本，特别是降低后期的推理成本。QLoRA就是量化版的LoRA，是在LoRA的基础上进行进一步量化，将原本用16位表示的参数改为用4位表示，从而在保证模型性能的同时极大地降低成本。
QLoRA是一种新的微调大语言模型的方法，它能够在节省内存的同时保证处理速度。其工作原理是先将大语言模型进行4位量化，显著减少模型的内存占用。接着，使用LoRA方法对量化的大语言模型进行微调。LoRA方法使得改进后的模型能够保留原始大语言模型的大部分准确性，同时具备更小的体积和更快的速度。
**4）检索增强生成**
检索增强生成（Retrieval Augmented Generation，RAG）。RAG是微调的一种替代方法，结合了自然语言生成和信息检索。RAG确保语言模型将外部最新知识或相关文档作为信息来源。这种技术弥合了通用模型广泛知识与最新知识需求之间的差距。
RAG = 检索技术 + 大语言模型提示增强。
图 7-1
相比于微调，RAG的一个优势在于信息管理。传统的微调将数据嵌入模型架构，实质上是“硬编码”知识，难以对知识进行修改。而RAG则支持检索数据源的持续更新，允许对检索到的数据进行移除或修订，从而确保模型生成结果的准确性。
RAG的操作概括为三个步骤：检索、增强和生成。从知识库中检索到的相关信息增强了提示词（prompt）的上下文信息，大模型通过结合外部信息与原始提示词生成问题的答案。
### 7.2 大模型量化技术
大模型训练完以后，通常会采取以下两种策略进行实际的产品部署：移动和边缘设备部署；云端部署。
模型量化是一种将神经网络模型中的参数从浮点数（FP32）转换为低比特宽度整数（如INT8、INT4等）的技术。
#### 7.2.1 量化的技术原理
模型量化本质上就是建立一种浮点数据和定点数据间的映射关系。过程示意：
图 7-2
将取值范围为[-T，T]的浮点数值映射到取值范围为[-127，127]的整数。
图 7-3
基于量化的基本概念将量化技术应用于大模型，通过对模型参数进行压缩和量化，可降低大模型的存储和计算复杂度。降低权重的精度，大模型的整体质量会受到一些影响，但这种影响取决于所使用的技术。相比之下，参数量更大的模型对精度变化的影响较小。参数量超过70B的模型即使量化到4位，其性能也不会受到影响。对于这些参数量较大的模型，4位量化似乎是性能和大小/速度之间的最佳平衡点。而对于参数量较小的模型，8位量化可能更合适。
模型量化并没有对模型的性能产生太大影响，同时还大幅度降低了显存的占用率。
#### 7.2.2 量化过程
模型量化方法的本质是函数映射，它在高精度的浮点数值和量化后低精度的定点数值之间建立了数据映射。根据量化函数的形式，量化可以分为线性量化和非线性量化。线性量化是目前最常用的量化方法，在工业界应用比较广泛的8位量化方案采用的都是线性量化。而非线性映射函数是多种多样的，通常需要根据不同场景的权值输入分布特点来确定使用何种映射方式。
根据量化发生的时刻，将量化技术分为三大类：量化感知训练（QAT），该技术将量化集成到训练过程中；量化感知微调（QAFT），该技术采用预训练的高精度模型，在保证模型质量的前提下使用较低的精度权重；训练后量化（PTQ），这种技术可在模型训练完之后，将大语言模型的参数转换为精度较低的数据类型。
#### 7.2.3 量化算法
两种比较有代表性的大语言模型量化算法：LLM.int8()和GPTQ。
**1）LLM.int8()量化**
LLM.int8()采用混合精度处理以及分离计算方式，即对离群值进行FP16矩阵运算，对非离群值特征进行线性量化，并将两者的计算结果相加。虽然LLM.int8()量化方案降低了显存的占用率并提高了准确度，但是这种分离计算方式大大降低了推理速度。INT8线性量化对于小参数模型的影响较小，在量化后模型效果可以几乎不变，并且可以直接用INT8进行计算，推理速度也可以得到提升。但是随着模型参数量的增加，离群值的出现会导致线性量化的效果会变差。改良后的LLM.int8()方法可以改善大参数量模型的效果，但由于采用了分离计算，推理速度会降低。
**2）GPTQ量化**
源自另一个量化方法OBQ（Optimal Brain Quantization），而OBQ 实际上是对OBS（Optimal Brain Surgeon，一种比较经典的剪枝方法）的改进。而OBS则来自OBD （Optimal Brain Damage，是杨立昆（Yann LeCun）在1990年提出的剪枝方法）。因此要想弄懂GPTQ，首先需要弄懂OBD、OBS、OBQ。
OBD开创了利用剪枝损失二阶信息挑选最佳权重的思路，OBS在此基础之上构造凸优化问题求解权重修正量，而OBQ则将OBS的思想应用模型量化。GPTQ提出若干优化措施进一步加速量化过程，使得量化技术在大语言模型中也能得到有效的应用。
### 7.3 AI Agent
AI Agent是一种能够感知环境、进行决策和执行动作的智能实体。
#### 7.3.1 背景介绍
美国斯坦福大学与谷歌合作搭建的名为Smallville的虚拟小镇开源，小镇上生活着25个AI Agent，它们有工作，会聊八卦，能组织社交活动，甚至举办情人节派对。
#### 7.3.2 什么是AI Agent
AI Agent通常是指一个能够自主规划和决策，运用多种工具完成复杂任务的系统。
在本书中，将AI Agent定义为可以感知环境、进行决策和执行动作，进而完成特定目标的智能系统。使用大语言模型作为核心计算引擎，能够感知周围环境，规划和决策执行步骤，综合利用各种工具来完成目标，在完成目标的过程中，通过交互学习和反思来优化决策。
#### 7.3.3 AI Agent 的组成部分
一个简单的 AI Agent 系统必须拥有 3 个核心模块：控制器（大脑）、感知、执行。
图 7-4
大模型驱动的自主AI Agent系统架构，其中包含记忆（Memory）、工具（Tools）、规划（Planning）、执行（Action）四大要素。基于大模型驱动的AI Agent所包含的4个核心模块：
图 7-5
#### 7.3.4 AI Agent的挑战与展望
AI Agent在交互灵活性与稳定性方面也面临着挑战。当前框架中，系统常因交互信息处理不当而运行不稳定，这主要归因于大语言模型作为概率模型，在部分场景下会产生随机性结果。
多模态支持主要涉及AI Agent对多模态信息的处理能力。当前学术界普遍采用将非文本模态信息转换为文字后再交由大语言模型处理的方案。然而，这种模态转换过程可能造成信息损失，并引发处理时延。

## （未完待续）
---