# 五、应用开发篇
## 第8章 企业大模型应用实战
### 8.1 企业基于提示工程解决业务问题
在大语言模型中，提示是用于引导模型生成文本的输入文本。提示可以是一个问题、一个主题、一段描述等，它可以帮助模型理解用户的意图，并生成相应的文本。提示的选择和设计非常重要，将直接影响生成文本的质量和准确性。这里，将提示分为4类：零样本提示（Zero-Shot）、少样本提示（Few-Shot）、思维链提示和任务分解。
#### 8.1.1 零样本提示
零样本提示是指在给定模型背景信息和数据的基础上，不提供任何相关案例参考，直接用自然语言指令对模型进行提问，让模型输出内容，从而完成一个任务。
#### 8.1.2 少样本提示
少样本提示是指在编写提示的过程中加入少量案例作为参考，使模型能更加充分地理解任务的目标，从而提升任务完成的准确性。
#### 8.1.3 思维链提示
在设置提示的过程中，除输入任务并等待输出结果外，还应该在提示中包含推理的中间步骤。思维链的本质是将复杂任务拆解为多个简单的子任务，体现一系列紧密相连的逻辑推理过程。思维链通常用于解决问题、做决策或进行推理。通过将复杂的问题分解为更简单的步骤或概念，思维链能够帮助我们以更清晰和有序的方式理解和解决问题。
不同于传统的提示从输入直接映射到输出<input→output>的方式，思维链方式实现了从输入到思维链再到输出的映射，即<input→reasoning chain→output>。
#### 8.1.4 任务分解
任务分解就是采用自顶向下的问题分解策略，首先将问题一次性拆解成若干子问题，之后逐个解决，进而汇总得到最终答案。这种任务分解方法和思维链类似，主要区别在于任务分解方法在分解任务的过程中还会进行多轮问答，针对子问题的回答会被加入下一次的提问。这种逐步填充问题上下文的方法，有效降低了多步推理问题的难度。
### 8.2 企业如何构建私有垂域大模型
大多数垂域大模型可以基于现有的大模型服务和开源通用大模型进行开发。
#### 8.2.1 开源大模型
比如：Meta公司的Llama 3、阿里巴巴的通义千问（Qwen）系列模型、微软的Phi-3等。
#### 8.2.2 构建垂域大模型的方式
通用的大语言模型在专业领域表现不佳的原因主要有如下两个：
**1）缺乏训练语料**：通用大语言模型使用的训练语料一般都是可以从公开渠道收集到的，但特定领域的语料一般难以在公开渠道收集，这些语料涉及企业的关键技术（Know-How），因而一般不会公开。
**2）产品设计考虑**：通用大模型考虑的是“通用”，因此其训练的首要目标是能够满足日常用户的多样化需求而非特定领域的需求，也就是不能对通用大模型“既要”“又要”“还要”。
构建一个面向特定专业领域大模型的挑战就变为怎么能够让大模型掌握特定领域的知识，为此可以放弃一些通用能力。主要有以下三种方式：
**1）大模型+知识库**：这是目前最简单的实现方法，即构建领域知识库，利用大模型的上下文学习能力，通过检索丰富问答中模型输入的上下文，让大模型可以准确地回答面对特定领域和企业相关的问题。
**2）PEFT**，这是一些开源领域模型常用的方式，这种方式通过P-Tuning或者LoRA等技术对模型进行微调，使其更适合回答特定领域的问题，比如法律和医疗领域的一些开源模型采用的就是这种方式。但是，使用这种方式微调的模型通常表现不佳，因为PEFT并不是用来让模型学会新知识的，而是用来让模型在处理特定任务时表现更好的。
**3）从预训练开始定制化训练**，这种方式是构建垂域大模型最有效的方法。该方法允许对从最初的词表构建、训练语料的配比，到模型结构设计的每一步进行定制。此外，这种方式严格遵循OpenAI的Pretrain→SFT→RLHF三段训练方法，理论上基于该训练方法可以构建出一个优秀的垂域大模型。这种方式的费用极高。
垂域大模型的训练过程分为以下3步：
图8-1
在构建垂域大模型时，可以考虑使用检索增强生成（RAG）技术。具体来说，就是模型先检索相关的知识，然后基于召回的知识进行回答，即基于检索增强生成回答。这种方式能减少模型的幻觉，保证答案的时效性，还能快速干预模型对特定问题的回答。
#### 8.2.3 企业构建垂域大模型的步骤
企业构建垂域大模型分为4个步骤：应用场景分析、数据准备、知识库构建和检索增强生成，以及模型训练。
**1）应用场景分析**
企业根据自身业务场景，分析场景类型，结合成本及积累的数据规模，选择构建大模型的方式。大模型的主要应用场景包括文生文、文生图、文生视频、文生音频、图生文、图生视频、多模态等。从应用类型角度，大语言模型主要分为任务型和非任务型两类。垂域大模型的构建方式主要有3种：基于知识库构建、基于参数微调构建和定制化训练构建。
**2）数据准备**
这里将数据分为3部分：无监督数据、单轮/多轮指令微调数据和RLHF训练数据。
- ① 无监督数据：如企业所保存的历史文档材料，这类数据通常不需要标注，只需要进行简单的清洗就可以使用。使用无监督数据是在预训练阶段注入领域知识的有效方式。
- ② 单轮/多轮指令微调数据：这部分数据需要经过人工标注整理，其中包含一系列问答对，常用于SFT和构建知识库，以实现检索增强。
- ③ RLHF训练数据：这部分数据同样需要经过人工标注整理，但与问答对不同，它主要用于对不同的回答结果进行排序。
**3）知识库构建和检索增强生成**
RAG是一项利用外部知识源提升大语言模型文本生成能力的技术。RAG技术背后的思想是在提问时引用外部数据，并将其提供给大语言模型，以增强其生成准确且相关答案的能力。
图8-2
RAG的数据处理流程：
图8-3
完整的RAG应用流程主要包含两个阶段：① 数据准备阶段：数据提取→文本分割→向量化（embedding）→数据入库。② 应用阶段：用户提问→数据检索（召回）→注入提示→大语言模型生成答案。
**4）模型训练**
由于垂域模型的构建方式不同，其模型训练方法也有所差异。主要介绍PEFT这种模型训练方法。全参数微调既占显存，速度又慢，相比之下，PEFT就显得很重要了。目前，使用最广泛的PEFT方法是LoRA，但Prefix-tuning、Prompt-tuning和P-tuning等也是比较常见的方法。
### 8.3 企业如何构建AI Agent
#### 8.3.1 AI Agent开发框架介绍
AutoGPT、AutoGen、LangChain、MetaGPT等。
#### 8.3.2 AI Agent的开发和部署
根据选择的框架来进行开发和部署。
## 第9章 企业大模型落地案例
### 9.1 B2C电商平台企业大模型应用落地案例
某中小型B2C电商企业在运营过程中面临大量用户评论文本分类、商品标签添加和信息提取等任务，若由运营团队成员手动进行处理（平均每个月80人参与），不仅费时且效率低下，而且对企业来说还要持续承担相应的人员成本。该企业仅拥有传统的IT系统开发团队，缺乏专业的NLP算法工程师来训练专门的AI模型实现自动化处理。因此，为高效处理这些任务并节约成本，该企业决定采用调用公有云厂商的大模型API，这样一来就无须招聘NLP算法工程师了。
### 9.2 CRM企业大模型落地案例
某知名CRM企业专注于为中小企业提供智能化的CRM解决方案，以SaaS模式为主提供服务，客户广泛分布于金融、电商、零售、教育等行业。随着市场竞争的加剧和客户需求的多样化，该企业面临以下痛点。① 数据处理与分析能力不足：传统的CRM系统难以高效处理和分析大量客户数据，需要进行大量的数据清洗与整理工作，工作台中的数据分析功能较弱，难以实现灵活定制化的客户自主分析功能，从而导致CRM产品亮点不足，不利于推广售卖。② 客户服务响应速度慢：由于系统里缺乏智能化的客户服务支持，客户咨询和投诉的响应速度较慢，进而影响了客户满意度。
根据市场调研和需求分析的结果，企业最终决定采用微调大模型方案，并选定清华智谱的ChatGLM3作为大模型底座。
### 9.3 科技公司基于大模型构建智能音箱任务型对话系统
利用大模型技术重构传统的智能对话系统。
### 9.4 Runway公司基于大模型引领图像、视频变革
# 六、未来展望篇
## 第10章 未来展望
### 10.1 大模型的当前发展阶段
技术成熟度曲线是一种用于评估和预测新技术发展趋势的工具。该曲线通过5个阶段来描述一项新技术从诞生到成熟的生命周期，帮助企业和投资者了解技术所处的发展阶段，以便做出更明智的决策。
图10-1
目前，大模型领域正处于期望膨胀期。随着人工智能技术的飞速发展，大模型作为其中的重要一环，受到了企业界、投资界乃至全社会的广泛关注。众多大模型企业先后获得高额融资，这反映了市场对这些公司前景的乐观预期。与此同时，各行各业也都在积极探索大模型的应用，试图将其融入自身的业务流程，以实现数字化转型和智能化升级。
### 10.2 AI未来发展趋势
在未来的发展进程中，AI有极大的可能性会遵循我们经常提到的二八法则。可以想象，在未来广阔的应用场景中，将会有高达80%的场景主要由大模型来发挥关键作用。另外20%的场景有可能需要依靠传统的小模型来妥善解决。
### 10.3 具身智能
目前，大模型更多是以软件形式出现在人们的视野当中，而在未来，大模型将融入硬件设备，成为机器人的中控大脑，为机器人提供全方位的感知、分析决策和行动规划能力，展现出巨大的发展潜力。该领域被称为具身智能。
### 10.4 未来新型企业组织架构
人工智能体具备一系列感知、任务规划与拆解、任务执行的能力，因此未来人机协作的模式也将逐步改变。
图10-2
未来新型企业组织架构：
图10-3
### 10.5 AGI
AGI，虚拟世界。

