# 三、企业落地步骤篇
## 第5章 大模型落地全流程
### 5.1 数据预处理
#### 5.1.1 具体要求
- 数据规模：需要更大规模的数据集进行微调和预训练，以确保模型能够广泛且深入地学习知识。数据集应尽可能涵盖丰富的语言环境和语义，以增强模型的泛化能力。
- 数据多样性：如果选择完全自研大模型，则训练数据应覆盖多种语义和语法结构，以提供全面的语言理解能力。数据来源应广泛，包括新闻、社交媒体、科技论文、公开数据集、GitHub等不同领域的文本，以确保模型具备广泛的应用能力。如果选择微调大模型，则需要花费一定精力将垂域的数据整理成合适的格式，并确保数据质量与安全性符合要求。
- 数据质量：数据整理和清洗阶段对保证数据质量尤为重要，必须处理缺失值、异常值、重复值等问题。对数据的标注应准确，以便模型能够学习正确的映射关系。
- 数据格式：①纯文本数据：文件格式包括.txt、.csv、.pdf，以及.doc和.docx等Word文档格式。②问答对数据：训练问答系统或对话系统的关键数据。每个问答对都包含一个问题和与之对应的答案。适合训练模型理解和回答问题，尤其是在构建智能助手、聊天机器人或搜索引擎时。③基于人类反馈的强化学习数据：基于人类反馈的强化学习（Reinforcement Learning from Human Feedback，RLHF）是一种利用人类反馈来优化模型性能的方法。在这个过程中，人类对模型的输出提供评价或建议，这些反馈数据被用作训练信号来调整模型参数，它们是训练或微调大模型要用到的重要数据。通常包括模型的原始输出、人类的评价或修改建议，以及可能的奖励信号（如评分、排名等）。
- 法律与道德合规性：符合法律法规和道德规范，尤其当内容涉及个人隐私和知识产权时。在使用数据前，应确保已获得必要的授权或许可。
- 技术可行性：数据的存储和传输应满足高效、安全和可靠的要求。对于超大规模的数据集，可能需要采用分布式存储和计算技术来提高处理效率。
#### 5.1.2 数据采集
构建大模型的关键前置步骤，涉及从各种来源获取相关数据。
- 真实业务数据：在正常业务流程中自然产生的，比如真实的对话、咨询、网站的访问日志、交易记录等。这些数据具有真实性和即时性，能够直接反映用户行为和业务需求。
- 抓取网上公开数据源：从公开网站上抓取大量信息，如公开的资料、论文、新闻、文章、代码、报告等。
- 人造数据：为了补充真实数据的不足或测试模型的泛化能力，可以人为制造一些数据。
#### 5.1.3 数据标注
是在获取大量数据之后，为了提升数据正确性和质量而进行的关键步骤。建议与专业标注公司合作，利用他们的专业知识和经验完成数据标注。主动学习策略能够帮助企业选择对模型训练最有价值的样本，由专家进行标注，进一步提升模型的准确性。
#### 5.1.4 数据清洗
- 纯文本格式（如.txt或.csv）的数据清洗：去除无关字符；数据规范化；处理缺失值；数据合并与分割。
- 问答对数据清洗：验证问答对的准确性；去除重复数据；标准化问题表述；格式化处理；口语化转换、常识化补充等处理。
- 用于RLHF的数据清洗：验证反馈的准确性；归一化反馈评分；处理缺失反馈；整合多源反馈。
在进行数据清洗时应当关注数据样本的均衡性。理想情况下，每个标签或场景都应该有足够多的训练样本，这样可以确保模型能够充分学习并准确预测。同时，每个标签对应的数据量应尽量保持平衡，或者至少要确保数据分布与实际业务场景相符。当遇到数据不均衡的问题时，可以采取一些策略来解决，比如数据增强。数据增强可以通过人工合成新数据（如使用模板生成后再进行人工标注），或借助模型自动生成数据，再结合人工审核或筛选的方式实现。

关于数据集的构建与划分，在数据量充足的情况下，通常会将数据分为训练集、验证集和测试集。
### 5.2 大模型评测
在选择大模型落地方案时，需要对大模型进行综合的性能评测，即根据一套完整的体系来评价大模型是否足够好，是否能匹配企业的需求。
#### 1．评测的价值和意义
模型选择、模型比较、模型改进、解释模型行为
#### 2．明确评测目标
常见的大模型评测目标：准确性评测：衡量模型预测与真实数据的接近程度。效率评测：评测模型在处理任务时的速度和资源消耗，包括模型的训练时间、推理时间、内存占用及计算资源的需求等。鲁棒性评测：评测模型对于输入数据的变化和噪声的敏感性。可解释性评测：评测模型提供的可解释性程度。对于某些高风险应用场景，如金融、医疗等，模型的可解释性至关重要。安全性评测：评测模型在面对恶意输入或攻击时的稳定性和安全性，包括但不限于对攻击样本的抵御能力，以及对隐私和安全性的保护等。多样性评测：评测模型在处理不同类型、风格或领域数据时的表现，包括领域适应性、多模态处理能力、文化和语言多样性，以及风格和主题多样性等方面。泛化能力评测：评测模型在从未见过的数据上的表现，通常难以用具体数值衡量。泛化能力强的模型能良好地适应新数据和新任务。
#### 3．数据准备
收集具有代表性的数据集，用于训练和测试模型。
#### 4．选择合适的评测指标
在模型的评测过程中，企业应当全面、细致地评测其性能，这就意味着需要综合考虑前文提及的一个或多个指标。比如 语音识别系统的评测往往更重视准确性和鲁棒性这两个指标。聊天机器人的应用可能更加看重多样性和可解释性。
#### 5．进行评测
使用独立的测试集对训练好的模型进行评估。
#### 6．结果分析与撰写报告
评测结束后要对评测结果进行详细的分析，包括各项指标的统计数据和模型的性能表现。
#### 7．迭代与优化
根据评测结果，企业需要对模型进行迭代和优化，以不断改善其性能，并满足各项评测目标。
#### 8．监控与维护
模型在生产环境部署后，企业需要持续监控其性能，并针对每个评测目标定期重新评测，确保模型始终保持最佳状态。
### 5.3 大模型与企业应用无缝衔接
在评测并建设完企业的大模型之后，需要采用一系列措施将大模型与企业已有应用进行整合与接入，这个过程通常也被称作大模型应用开发。为了确保大模型与企业实际业务高度契合，企业应在这个过程中实施以下步骤。
#### 1．明确业务需求与目标
确定应用场景；设定最小化可行产品（MVP）并持续迭代。
#### 2．进行技术选型与框架安装
选择合适的开源大模型框架，安装和配置框架。
#### 3．搭建架构
搭建整体架构：采用“特定类型的数据库+ Prompt + 通用大模型”的架构，实现从用户输入到应用输出的全流程贯通。
搭建向量数据库：由于大模型应用需要进行向量语义检索，一般使用诸如Faiss之类的向量数据库，收集数据并进行预处理，再进行向量化并存储到向量数据库中。
实现外部系统调用：企业需要的知识既不在大模型中，也不在向量数据库中，则可能需要大模型使用类似Function Calling、MCP等之类的技术手段，来实现外部系统调用，从而执行进一步的知识检索、API调用、执行外部任务等。
#### 4．完成集成与部署
集成模型：将训练好的大模型集成到应用中。
部署应用：选择合适的服务器和云平台进行模型部署。
#### 5．进行测试与优化
进行全面测试：包括功能测试、性能测试、安全测试等，确保应用的质量。优化性能。
#### 6．进行维护与更新
进行监控与维护；进行更新与升级。
### 5.4 部署上线
在部署方案的选择方面，企业拥有多种可行的途径。其中，云服务部署是一种备受青睐的方式，企业可以充分利用云服务提供商的强大基础设施，通过云平台快速扩展资源，并根据实际业务的需求灵活地调整计算能力。
如果企业自身拥有充足的硬件资源和强大的 IT 支持团队，那么在本地服务器上部署模型也是一个值得考虑的选项。
此外，运用 Docker 等容器技术来部署模型也是一个极具吸引力的选择。
在部署过程中，大模型对不同芯片的适配工作也不容忽视。例如，企业可能需要考虑如何让大模型适配华为昇腾、Intel、AMD 等芯片。不同芯片在架构、性能特点和指令集等方面存在差异，要实现良好的适配，需要对大模型进行针对性的优化和调整。
### 5.5 效果评估与数据反馈闭环
待大模型成功上线之后，企业应定期进行全面的效果评估。企业务必定期对业务的投资回报率进行全面的评估并细致分析大模型带来的实际收益与运行维护成本的比例关系。
### 5.6 大模型迭代
企业需要持续地投入资源对大模型进行迭代与优化。企业持续迭代大模型的建议：
#### 1．数据收集与更新
不断收集最新的业务数据，包括用户反馈、市场趋势、业务变化等，以反映模型应用的实际环境和需求；其次要定期更新数据集，确保模型训练基于最新、最全面的数据。
#### 2．模型评估与优化
定期对模型进行评估，识别性能瓶颈和存在的问题，根据评估结果对模型进行优化，包括调整模型结构、改变参数设置、优化算法等。
#### 3．算法改进与创新
关注最新的AI技术和算法进展，评估其对企业大模型的适用性。结合自身业务需求和技术特点，进行算法改进和创新，提高模型性能。
#### 4．平台与工具升级
#### 5．安全与隐私保护
#### 6．用户反馈与参与
#### 7．团队协作与知识共享
### 5.7 大模型安全建设
确保数据的安全，重视模型训练的安全性，防止信息泄漏和被攻击，规避涉黄、涉政、涉恐等敏感内容，防止模型盗用，进行对抗攻击防护，全面的模型评估和验证，建立严格的访问控制和权限管理机制。
### 5.8 大模型算法备案
大模型产品直接或间接用于商业活动，尤其是直接面向个人消费者用户，在国内需要进行大模型算法备案，在国外需要遵循各国家或地区的相关规定。
**算法备案合规的要点**：内容合规性，数据处理活动的合法性，明确服务协议，数据来源合规性，内容标识要求，消费者权益保护，安全性和可靠性保障。在算法备案中，针对算法方面的描述应当详细且全面，以确保审核机构能够充分理解算法的工作原理、潜在风险及相应的防控措施。
**算法备案的流程**：1）登录互联网信息服务算法备案系统。2）填报主体信息并提交。3）提交算法安全主体责任落实情况报告。4）提交证件信息。5）提交算法相关信息。6）提交《算法安全自评估报告》。7）提交产品功能信息。
**国内已通过备案的大模型产品**：截至2024年4月，国家互联网信息办公室公布了生成式人工智能服务已备案信息，我国已有超过100个生成式人工智能服务产品办理了国内备案手续。备案的大模型产品文心一言、智谱清言、云雀等已被广泛应用于搜索引擎、对话生成、语音识别等多个领域。
### 5.9 大模型内容的版权问题
大模型输出内容的版权问题及训练数据集的知识归属和付费问题是既复杂又敏感的问题。在处理这些问题时，需要综合考虑多个层面的因素，包括法律法规、版权声明、数据的来源及行业实践等。

## （未完待续）
---